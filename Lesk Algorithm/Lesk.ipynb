{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package semcor to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package semcor is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"semcor\") \n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import semcor \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from string import punctuation\n",
    "from num2words import num2words\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_tagged_sents = semcor.tagged_sents(tag='sem')\n",
    "semcor_untagged_sents = semcor.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "#online loading from api\n",
    "from gensim.models import KeyedVectors\n",
    "path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "#local loading\n",
    "# word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), Tree(Lemma('state.v.01.say'), ['said']), Tree(Lemma('friday.n.01.Friday'), ['Friday']), ['an'], Tree(Lemma('probe.n.01.investigation'), ['investigation']), ['of'], Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']), [\"'s\"], Tree(Lemma('late.s.03.recent'), ['recent']), Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']), Tree(Lemma('produce.v.04.produce'), ['produced']), ['``'], ['no'], Tree(Lemma('evidence.n.01.evidence'), ['evidence']), [\"''\"], ['that'], ['any'], Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']), Tree(Lemma('happen.v.01.take_place'), ['took', 'place']), ['.']], [['The'], Tree(Lemma('jury.n.01.jury'), ['jury']), Tree(Lemma('far.r.02.far'), ['further']), Tree(Lemma('state.v.01.say'), ['said']), ['in'], Tree(Lemma('term.n.02.term'), ['term']), Tree(Lemma('end.n.02.end'), ['end']), Tree(Lemma('presentment.n.01.presentment'), ['presentments']), ['that'], ['the'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['City', 'Executive', 'Committee'])]), [','], ['which'], Tree(Lemma('own.v.01.have'), ['had']), Tree(Lemma('overall.s.02.overall'), ['over-all']), Tree(Lemma('mission.n.03.charge'), ['charge']), ['of'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), [','], ['``'], Tree(Lemma('deserve.v.01.deserve'), ['deserves']), ['the'], Tree(Lemma('praise.n.01.praise'), ['praise']), ['and'], Tree(Lemma('thanks.n.01.thanks'), ['thanks']), ['of'], ['the'], Tree(Lemma('location.n.01.location'), [Tree('NE', ['City', 'of', 'Atlanta'])]), [\"''\"], ['for'], ['the'], Tree(Lemma('manner.n.01.manner'), ['manner']), ['in'], ['which'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), ['was'], Tree(Lemma('conduct.v.01.conduct'), ['conducted']), ['.']], ...]\n",
      "[['The'], Tree(Lemma('jury.n.01.jury'), ['jury']), Tree(Lemma('far.r.02.far'), ['further']), Tree(Lemma('state.v.01.say'), ['said']), ['in'], Tree(Lemma('term.n.02.term'), ['term']), Tree(Lemma('end.n.02.end'), ['end']), Tree(Lemma('presentment.n.01.presentment'), ['presentments']), ['that'], ['the'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['City', 'Executive', 'Committee'])]), [','], ['which'], Tree(Lemma('own.v.01.have'), ['had']), Tree(Lemma('overall.s.02.overall'), ['over-all']), Tree(Lemma('mission.n.03.charge'), ['charge']), ['of'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), [','], ['``'], Tree(Lemma('deserve.v.01.deserve'), ['deserves']), ['the'], Tree(Lemma('praise.n.01.praise'), ['praise']), ['and'], Tree(Lemma('thanks.n.01.thanks'), ['thanks']), ['of'], ['the'], Tree(Lemma('location.n.01.location'), [Tree('NE', ['City', 'of', 'Atlanta'])]), [\"''\"], ['for'], ['the'], Tree(Lemma('manner.n.01.manner'), ['manner']), ['in'], ['which'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), ['was'], Tree(Lemma('conduct.v.01.conduct'), ['conducted']), ['.']]\n"
     ]
    }
   ],
   "source": [
    "print(semcor_tagged_sents)\n",
    "print(semcor_tagged_sents[1])\n",
    "#word_net.synsets('dog')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_SW = [\n",
    "    \"''\",\n",
    "    \"'s\",\n",
    "    \"``\"\n",
    "]\n",
    "\n",
    "SW = stopwords.words(\"english\")\n",
    "SW += [p for p in punctuation]\n",
    "SW += EXTRA_SW\n",
    "# if '(' in SW:\n",
    "#     print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "semcor_sents = semcor.sents()\n",
    "# for sentence in semcor_sents:\n",
    "#     for word in sentence:\n",
    "#         if word in model_w2v:\n",
    "#             vectors[word] = model_w2v.get_vector(word)\n",
    "print(semcor_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance('Folton',str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset name :   [Synset('cricket.n.01'), Synset('cricket.n.02'), Synset('cricket.v.01')]\n",
      "\n",
      "Synset meaning :  leaping insect; male makes chirping noises by rubbing the forewings together\n",
      "[Synset('european_house_cricket.n.01'), Synset('field_cricket.n.01'), Synset('mole_cricket.n.01'), Synset('tree_cricket.n.01')]\n",
      "leaping insect; male makes chirping noises by rubbing the forewings together\n",
      "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
      "play cricket\n"
     ]
    }
   ],
   "source": [
    "syn = wn.synsets('cricket')\n",
    " \n",
    "print (\"Synset name :  \", syn)\n",
    " \n",
    "# Defining the word\n",
    "print (\"\\nSynset meaning : \", syn[0].definition())\n",
    "print(syn[0].hyponyms())\n",
    "for w in syn:\n",
    "    print(w.definition())\n",
    "# print(syn[0].hyponyms()[1].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), Tree(Lemma('state.v.01.say'), ['said']), Tree(Lemma('friday.n.01.Friday'), ['Friday']), ['an'], Tree(Lemma('probe.n.01.investigation'), ['investigation']), ['of'], Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']), [\"'s\"], Tree(Lemma('late.s.03.recent'), ['recent']), Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']), Tree(Lemma('produce.v.04.produce'), ['produced']), ['``'], ['no'], Tree(Lemma('evidence.n.01.evidence'), ['evidence']), [\"''\"], ['that'], ['any'], Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']), Tree(Lemma('happen.v.01.take_place'), ['took', 'place']), ['.']], [['The'], Tree(Lemma('jury.n.01.jury'), ['jury']), Tree(Lemma('far.r.02.far'), ['further']), Tree(Lemma('state.v.01.say'), ['said']), ['in'], Tree(Lemma('term.n.02.term'), ['term']), Tree(Lemma('end.n.02.end'), ['end']), Tree(Lemma('presentment.n.01.presentment'), ['presentments']), ['that'], ['the'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['City', 'Executive', 'Committee'])]), [','], ['which'], Tree(Lemma('own.v.01.have'), ['had']), Tree(Lemma('overall.s.02.overall'), ['over-all']), Tree(Lemma('mission.n.03.charge'), ['charge']), ['of'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), [','], ['``'], Tree(Lemma('deserve.v.01.deserve'), ['deserves']), ['the'], Tree(Lemma('praise.n.01.praise'), ['praise']), ['and'], Tree(Lemma('thanks.n.01.thanks'), ['thanks']), ['of'], ['the'], Tree(Lemma('location.n.01.location'), [Tree('NE', ['City', 'of', 'Atlanta'])]), [\"''\"], ['for'], ['the'], Tree(Lemma('manner.n.01.manner'), ['manner']), ['in'], ['which'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), ['was'], Tree(Lemma('conduct.v.01.conduct'), ['conducted']), ['.']], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor_tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sent):\n",
    "    sent_vec = np.zeros(300)\n",
    "    for word in sent:\n",
    "        if word in word2vec:\n",
    "            sent_vec += word2vec.get_vector(word)\n",
    "    return sent_vec        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumber(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number2word(word):\n",
    "    if isNumber(word) and word != 'infinity' and word != 'nan':\n",
    "        return num2words(word)\n",
    "    else: \n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def most_similar_sense(word,sentence,tag_return=False):\n",
    "    updated_sentence = [w for w in sentence if (w not in SW) and (w.isalnum())]\n",
    "    if word in updated_sentence:\n",
    "        updated_sentence.remove(word)\n",
    "    if(len(updated_sentence) == 0):\n",
    "        return 'none'\n",
    "    \n",
    "    context_vec = np.zeros(300)\n",
    "    \n",
    "    context_vec = sentence_vector(updated_sentence)\n",
    "    \n",
    "    sense_vec_dict = {}\n",
    "    \n",
    "    all_senses = wn.synsets(word)\n",
    "    \n",
    "    if len(all_senses)==0:\n",
    "        return 'none'\n",
    "    \n",
    "    for sense in all_senses:\n",
    "        sense_vec_dict[sense] = []\n",
    "        sense_sent = sense.definition().split()\n",
    "        sense_sent = [w for w in sense_sent if (w not in SW) and (w.isalnum())]\n",
    "        sense_vec = sentence_vector(sense_sent)\n",
    "        sense_vec_dict[sense].append(sense_vec)\n",
    "        \n",
    "        hyponym_sent_list = sense.hyponyms()\n",
    "        for hyponym_sent in hyponym_sent_list:\n",
    "            hyponym_sent = hyponym_sent.definition().split()\n",
    "            hyponym_vec = sentence_vector(hyponym_sent)\n",
    "            sense_vec_dict[sense].append(hyponym_vec)\n",
    "        for hypernym in sense.hypernyms():\n",
    "            hypernym_sent = hypernym.definition().split()\n",
    "            hypernym_sent = [w for w in hypernym_sent if (w not in SW) and (w.isalnum())]\n",
    "            hypernym_vec = sentence_vector(hypernym_sent)\n",
    "            sense_vec_dict[sense].append(hypernym_vec)\n",
    "    \n",
    "    if len(sense_vec_dict.keys())==0:\n",
    "        return 'none'\n",
    "    cos_sim_list = []\n",
    "    for key, value in sense_vec_dict.items():\n",
    "        cos_sim_list.append((key,word2vec.cosine_similarities(context_vec,value).mean()))\n",
    "    cos_sim_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    if tag_return:\n",
    "        return str(cos_sim_list[0][0])[8:-2],cos_sim_list[0][0]\n",
    "    else:\n",
    "        return str(cos_sim_list[0][0])[8:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'school.n.05'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "most_similar_sense('school',['The','boy','goes','to','school','2','or','infinite','times','a','day','.'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tagged_sents,untagged_sents):\n",
    "    actual = []\n",
    "    pred = []\n",
    "    count = 0\n",
    "    for i in range(len(tagged_sents)):\n",
    "        for j in range(len(tagged_sents[i])):\n",
    "            \n",
    "            word = ''\n",
    "            if isinstance(tagged_sents[i][j],nltk.Tree):\n",
    "                try:\n",
    "                    if tagged_sents[i][j].height() == 3:\n",
    "                        for tree in tagged_sents[i][j]:\n",
    "                            if(tree.label() == 'NE'):\n",
    "                                word = \"\".join(tree.leaves())\n",
    "                                actual.append('NE')\n",
    "                                \n",
    "                    else:\n",
    "                        word = \"\".join(tagged_sents[i][j].leaves())\n",
    "                        sense = tagged_sents[i][j].label().synset().name()\n",
    "                        actual.append(sense)\n",
    "                except:\n",
    "                    \n",
    "                    if (tagged_sents[i][j].label()=='NE'):\n",
    "                        word = \"\".join(tagged_sents[i][j].leaves())\n",
    "                        actual.append('NE')\n",
    "                    else:\n",
    "                        word = \"\".join(tagged_sents[i][j].leaves())\n",
    "                        actual.append(sense)\n",
    "                \n",
    "            else:\n",
    "                actual.append('none')\n",
    "                word = \"\".join(tagged_sents[i][j])\n",
    "            pred.append(most_similar_sense(word,untagged_sents[i]))\n",
    "            \n",
    "        if count%500 == 0:\n",
    "            print(\"Steps Completed \",count)\n",
    "        count += 1\n",
    "    return actual,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_tagged_sents = semcor.tagged_sents(tag='sem')\n",
    "semcor_untagged_sents = semcor.sents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps Completed  0\n",
      "Steps Completed  500\n",
      "Steps Completed  1000\n",
      "Steps Completed  1500\n",
      "Steps Completed  2000\n",
      "Steps Completed  2500\n",
      "Steps Completed  3000\n",
      "Steps Completed  3500\n",
      "Steps Completed  4000\n",
      "Steps Completed  4500\n",
      "Steps Completed  5000\n",
      "Steps Completed  5500\n",
      "Steps Completed  6000\n",
      "Steps Completed  6500\n",
      "Steps Completed  7000\n",
      "Steps Completed  7500\n",
      "Steps Completed  8000\n",
      "Steps Completed  8500\n",
      "Steps Completed  9000\n",
      "Steps Completed  9500\n",
      "Steps Completed  10000\n",
      "Steps Completed  10500\n",
      "Steps Completed  11000\n",
      "Steps Completed  11500\n",
      "Steps Completed  12000\n",
      "Steps Completed  12500\n",
      "Steps Completed  13000\n",
      "Steps Completed  13500\n",
      "Steps Completed  14000\n",
      "Steps Completed  14500\n",
      "Steps Completed  15000\n",
      "Steps Completed  15500\n",
      "Steps Completed  16000\n",
      "Steps Completed  16500\n",
      "Steps Completed  17000\n",
      "Steps Completed  17500\n",
      "Steps Completed  18000\n",
      "Steps Completed  18500\n",
      "Steps Completed  19000\n",
      "Steps Completed  19500\n",
      "Steps Completed  20000\n",
      "Steps Completed  20500\n",
      "Steps Completed  21000\n",
      "Steps Completed  21500\n",
      "Steps Completed  22000\n",
      "Steps Completed  22500\n",
      "Steps Completed  23000\n",
      "Steps Completed  23500\n",
      "Steps Completed  24000\n",
      "Steps Completed  24500\n",
      "Steps Completed  25000\n",
      "Steps Completed  25500\n",
      "Steps Completed  26000\n",
      "Steps Completed  26500\n",
      "Steps Completed  27000\n",
      "Steps Completed  27500\n",
      "Steps Completed  28000\n",
      "Steps Completed  28500\n",
      "Steps Completed  29000\n",
      "Steps Completed  29500\n",
      "Steps Completed  30000\n",
      "Steps Completed  30500\n",
      "Steps Completed  31000\n",
      "Steps Completed  31500\n",
      "Steps Completed  32000\n",
      "Steps Completed  32500\n",
      "Steps Completed  33000\n",
      "Steps Completed  33500\n",
      "Steps Completed  34000\n",
      "Steps Completed  34500\n",
      "Steps Completed  35000\n",
      "Steps Completed  35500\n",
      "Steps Completed  36000\n",
      "Steps Completed  36500\n",
      "Steps Completed  37000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "actual,pred = predict(semcor_tagged_sents,semcor_untagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37176"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semcor_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778587\n",
      "778587\n"
     ]
    }
   ],
   "source": [
    "print(len(actual))\n",
    "print(len(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = []\n",
    "for i in range(len(semcor_tagged_sents)):\n",
    "    for j in range(len(semcor_tagged_sents[i])):\n",
    "        if isinstance(semcor_tagged_sents[i][j],nltk.Tree):\n",
    "            try:\n",
    "                if semcor_tagged_sents[i][j].height() == 3:\n",
    "                    for tree in semcor_tagged_sents[i][j]:\n",
    "                        if(tree.label() == 'NE'):\n",
    "                            senses.append('NE')\n",
    "                            \n",
    "                else:\n",
    "                    sense = semcor_tagged_sents[i][j].label().synset().name()\n",
    "                    senses.append(sense)\n",
    "                    \n",
    "            except:\n",
    "                if (semcor_tagged_sents[i][j].label()=='NE'):\n",
    "                    senses.append('NE')\n",
    "                else:\n",
    "                    sense = semcor_tagged_sents[i][j].label()\n",
    "                    senses.append(sense)\n",
    "        else:\n",
    "            senses.append('none')\n",
    "senses.append('notag')\n",
    "senses = list(set(senses))\n",
    "senses = {senses[i]:i for i in range(len(senses))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [senses[i] for i in actual]\n",
    "y_pred = [senses.get(i, senses['notag']) for i in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4922108897271596\n",
      "0.5743500313937702\n",
      "0.7567236936581859\n",
      "0.4922108897271596\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "print(sm.accuracy_score(y_true, y_pred))\n",
    "print(sm.f1_score(y_true, y_pred, average='weighted'))\n",
    "print(sm.precision_score(y_true, y_pred,average='weighted'))\n",
    "print(sm.recall_score(y_true, y_pred,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence(sentence):\n",
    "    unc_sen = sentence\n",
    "    sentence = sentence.split()\n",
    "    sentence = [w for w in sentence if (w not in SW) and (w.isalnum())]\n",
    "    print(\"===\"*40)\n",
    "    print(\"Sentence: \",unc_sen)\n",
    "    print(\"===\"*40)\n",
    "    for word in sentence:\n",
    "        sense = most_similar_sense(word,sentence,True)\n",
    "        if sense == 'none':\n",
    "            print(\"Word: \",word)\n",
    "            print(\"Sense: \", sense)\n",
    "        else:\n",
    "            print(\"Word: \",word)\n",
    "            print(\"Sense: \", sense[0])\n",
    "            print(\"Definition of sense: \", sense[1].definition())\n",
    "        print('---'*20)\n",
    "    print(\"===\"*40)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Sentence:   What is the interest on this loan ?\n",
      "========================================================================================================================\n",
      "Word:  What\n",
      "Sense:  none\n",
      "------------------------------------------------------------\n",
      "Word:  interest\n",
      "Sense:  interest.n.04\n",
      "Definition of sense:  a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "------------------------------------------------------------\n",
      "Word:  loan\n",
      "Sense:  loan.n.01\n",
      "Definition of sense:  the temporary provision of money (usually at interest)\n",
      "------------------------------------------------------------\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "new_sentence = ' What is the interest on this loan ?'\n",
    "test_sentence(new_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9b58781d1fa8134ac2ec6cc898ef119ce6179b951012c321b666aa023aba281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
