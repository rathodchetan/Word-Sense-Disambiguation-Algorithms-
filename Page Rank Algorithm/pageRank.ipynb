{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package semcor to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package semcor is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"semcor\") \n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import semcor \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from string import punctuation\n",
    "from num2words import num2words\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import networkx as nx\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_tagged_sents = semcor.tagged_sents(tag='sem')\n",
    "semcor_untagged_sents = semcor.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "#online loading from api\n",
    "from gensim.models import KeyedVectors\n",
    "path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "#local loading\n",
    "# word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_SW = [\n",
    "    \"''\",\n",
    "    \"'s\",\n",
    "    \"``\"\n",
    "]\n",
    "\n",
    "SW = stopwords.words(\"english\")\n",
    "SW += [p for p in punctuation]\n",
    "SW += EXTRA_SW\n",
    "# if '(' in SW:\n",
    "#     print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sent):\n",
    "    sent_vec = np.zeros(300)\n",
    "    for word in sent:\n",
    "        if word in word2vec:\n",
    "            sent_vec += word2vec.get_vector(word)\n",
    "    return sent_vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = []\n",
    "for i in range(len(semcor_tagged_sents)):\n",
    "    for j in range(len(semcor_tagged_sents[i])):\n",
    "        if isinstance(semcor_tagged_sents[i][j],nltk.Tree):\n",
    "            try:\n",
    "                if semcor_tagged_sents[i][j].height() == 3:\n",
    "                    for tree in semcor_tagged_sents[i][j]:\n",
    "                        if(tree.label() == 'NE'):\n",
    "                            senses.append('NE')\n",
    "                            \n",
    "                else:\n",
    "                    sense = semcor_tagged_sents[i][j].label().synset().name()\n",
    "                    senses.append(sense)\n",
    "                    \n",
    "            except:\n",
    "                if (semcor_tagged_sents[i][j].label()=='NE'):\n",
    "                    senses.append('NE')\n",
    "                else:\n",
    "                    sense = semcor_tagged_sents[i][j].label()\n",
    "                    senses.append(sense)\n",
    "        else:\n",
    "            senses.append('none')\n",
    "senses.append('notag')\n",
    "senses = list(set(senses))\n",
    "senses = {senses[i]:i for i in range(len(senses))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_for_sentence(sentence,isTest = False):\n",
    "    updated_sent = sentence\n",
    "    G = nx.Graph()\n",
    "    word_senses = []\n",
    "    list_of_all = []\n",
    "    sense_vec_dict = {}\n",
    "    sense_vec_dict['none'] = []\n",
    "    sense_vec_dict['none'].append(np.zeros(300))\n",
    "    for word in updated_sent:\n",
    "        all_senses = wn.synsets(word)\n",
    "        \n",
    "        list_senses = []\n",
    "        if len(all_senses) == 0:\n",
    "            # print(word,'1')\n",
    "            all_senses = ['none']\n",
    "            list_of_all.append('none')\n",
    "            list_senses.append((len(list_of_all)-1,'none'))\n",
    "        else:\n",
    "            # print(word,'2')\n",
    "            for sense in all_senses:\n",
    "                list_of_all.append(sense)\n",
    "                list_senses.append((len(list_of_all)-1,sense))\n",
    "                sense_vec_dict[sense] = []\n",
    "                sense_sent = sense.definition().split()\n",
    "                sense_sent = [w for w in sense_sent if (w not in SW) and (w.isalnum())]\n",
    "                sense_vec = sentence_vector(sense_sent)\n",
    "                sense_vec_dict[sense].append(sense_vec)\n",
    "        word_senses.append(list_senses)\n",
    "\n",
    "    for i in range(len(word_senses)-1):\n",
    "        for j in range(len(word_senses[i])):\n",
    "            for k in range(len(word_senses[i+1])):\n",
    "                cos_sim  = cosine_similarity(sense_vec_dict[word_senses[i][j][1]][0].reshape(1,-1),sense_vec_dict[word_senses[i+1][k][1]][0].reshape(1,-1))\n",
    "                G.add_edge(word_senses[i][j][0], word_senses[i+1][k][0],weight = cos_sim[0][0])\n",
    "    rank_output = dict()\n",
    "    try:\n",
    "        rank_output = nx.pagerank(G,max_iter=1000)\n",
    "    except:\n",
    "        for i in range(G.number_of_nodes()):\n",
    "            rank_output[i] = 0\n",
    "\n",
    "    new_list = []\n",
    "    for i in range(len(word_senses)):\n",
    "        max_val = -1\n",
    "        max_sense = ''\n",
    "        for j in range(len(word_senses[i])):\n",
    "            if rank_output[word_senses[i][j][0]] >= max_val:\n",
    "                max_val = rank_output[word_senses[i][j][0]]\n",
    "                max_sense = word_senses[i][j][1]\n",
    "        if str(max_sense) == 'none':\n",
    "            new_list.append('none')\n",
    "        else:\n",
    "            if isTest:\n",
    "                new_list.append(max_sense)\n",
    "            else:\n",
    "                new_list.append(str(max_sense)[8:-2])\n",
    "        \n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tagged_sents,untagged_sents):\n",
    "    actual = []\n",
    "    pred = []\n",
    "    count = 0\n",
    "    for i in range(len(tagged_sents)):\n",
    "        sentence = []\n",
    "        # print(i)\n",
    "        if len(tagged_sents[i])<=1:\n",
    "            continue\n",
    "        for j in range(len(tagged_sents[i])):\n",
    "            \n",
    "            word = ''\n",
    "\n",
    "        \n",
    "            if isinstance(tagged_sents[i][j],nltk.Tree):\n",
    "                try:\n",
    "                    if tagged_sents[i][j].height() == 3:\n",
    "                        for tree in tagged_sents[i][j]:\n",
    "                            if(tree.label() == 'NE'):\n",
    "                                word = \"_\".join(tree.leaves())\n",
    "                                actual.append('NE')\n",
    "                                \n",
    "                    else:\n",
    "                       \n",
    "                        word = \"_\".join(tagged_sents[i][j].leaves())\n",
    "                        sense = tagged_sents[i][j].label().synset().name()\n",
    "                        actual.append(sense)\n",
    "\n",
    "                except:\n",
    "                    \n",
    "                    if (tagged_sents[i][j].label()=='NE'):\n",
    "                        word = \"_\".join(tagged_sents[i][j].leaves())\n",
    "                        actual.append('NE')\n",
    "                    else:\n",
    "                        sense = tagged_sents[i][j].label()\n",
    "                        word = \"_\".join(tagged_sents[i][j].leaves())\n",
    "                        actual.append(sense)\n",
    "            else:\n",
    "               \n",
    "                actual.append('none')\n",
    "                word = \"_\".join(tagged_sents[i][j])\n",
    "            sentence.append(word)\n",
    "        if count%500 == 0:\n",
    "            print(\"Steps Completed \",count)\n",
    "        count += 1\n",
    "        \n",
    "        pred += graph_for_sentence(sentence)\n",
    "    return actual,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_tagged_sents = semcor.tagged_sents(tag='sem')\n",
    "semcor_untagged_sents = semcor.sents()\n",
    "semcor_pos_tagged_sents = semcor.tagged_sents(tag='pos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps Completed  0\n",
      "Steps Completed  500\n",
      "Steps Completed  1000\n",
      "Steps Completed  1500\n",
      "Steps Completed  2000\n",
      "Steps Completed  2500\n",
      "Steps Completed  3000\n",
      "Steps Completed  3500\n",
      "Steps Completed  4000\n",
      "Steps Completed  4500\n",
      "Steps Completed  5000\n",
      "Steps Completed  5500\n",
      "Steps Completed  6000\n",
      "Steps Completed  6500\n",
      "Steps Completed  7000\n",
      "Steps Completed  7500\n",
      "Steps Completed  8000\n",
      "Steps Completed  8500\n",
      "Steps Completed  9000\n",
      "Steps Completed  9500\n",
      "Steps Completed  10000\n",
      "Steps Completed  10500\n",
      "Steps Completed  11000\n",
      "Steps Completed  11500\n",
      "Steps Completed  12000\n",
      "Steps Completed  12500\n",
      "Steps Completed  13000\n",
      "Steps Completed  13500\n",
      "Steps Completed  14000\n",
      "Steps Completed  14500\n",
      "Steps Completed  15000\n",
      "Steps Completed  15500\n",
      "Steps Completed  16000\n",
      "Steps Completed  16500\n",
      "Steps Completed  17000\n",
      "Steps Completed  17500\n",
      "Steps Completed  18000\n",
      "Steps Completed  18500\n",
      "Steps Completed  19000\n",
      "Steps Completed  19500\n",
      "Steps Completed  20000\n",
      "Steps Completed  20500\n",
      "Steps Completed  21000\n",
      "Steps Completed  21500\n",
      "Steps Completed  22000\n",
      "Steps Completed  22500\n",
      "Steps Completed  23000\n",
      "Steps Completed  23500\n",
      "Steps Completed  24000\n",
      "Steps Completed  24500\n",
      "Steps Completed  25000\n",
      "Steps Completed  25500\n",
      "Steps Completed  26000\n",
      "Steps Completed  26500\n",
      "Steps Completed  27000\n",
      "Steps Completed  27500\n",
      "Steps Completed  28000\n",
      "Steps Completed  28500\n",
      "Steps Completed  29000\n",
      "Steps Completed  29500\n",
      "Steps Completed  30000\n",
      "Steps Completed  30500\n",
      "Steps Completed  31000\n",
      "Steps Completed  31500\n",
      "Steps Completed  32000\n",
      "Steps Completed  32500\n",
      "Steps Completed  33000\n",
      "Steps Completed  33500\n",
      "Steps Completed  34000\n",
      "Steps Completed  34500\n",
      "Steps Completed  35000\n",
      "Steps Completed  35500\n",
      "Steps Completed  36000\n",
      "Steps Completed  36500\n",
      "Steps Completed  37000\n"
     ]
    }
   ],
   "source": [
    "actual,pred = predict(semcor_tagged_sents,semcor_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778579\n",
      "778579\n"
     ]
    }
   ],
   "source": [
    "print(len(actual))\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_actual = []\n",
    "new_pred = []\n",
    "k=0\n",
    "for i in range(len(actual)):\n",
    "    if actual[i] == 'none' or actual[i] == 'NE':\n",
    "        continue\n",
    "    if actual[i].split('.')[1] == 'n':\n",
    "        new_actual.append(actual[i])\n",
    "        new_pred.append(pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79313\n",
      "79313\n"
     ]
    }
   ],
   "source": [
    "print(len(new_actual))\n",
    "print(len(new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_n = [senses[i] for i in new_actual]\n",
    "y_pred_n = [senses.get(i, senses['none']) for i in new_pred]\n",
    "y_pred = [senses.get(i, senses['none']) for i in pred]\n",
    "y_true = [senses[i] for i in actual]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for All tagset\n",
      "0.5717210456485469\n",
      "0.6067095872539181\n",
      "0.6914588874335078\n",
      "0.5717210456485469\n",
      "========================================================================================================================\n",
      "Scores for Nouns\n",
      "0.3186488974064781\n",
      "0.3540028532501026\n",
      "0.5837607117961402\n",
      "0.3186488974064781\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "print(\"Scores for All tagset\")\n",
    "print(sm.accuracy_score(y_true, y_pred))\n",
    "print(sm.f1_score(y_true, y_pred, average='weighted'))\n",
    "print(sm.precision_score(y_true, y_pred,average='weighted'))\n",
    "print(sm.recall_score(y_true, y_pred,average='weighted'))\n",
    "\n",
    "print(\"===\"*40)\n",
    "print('Scores for Nouns')\n",
    "print(sm.accuracy_score(y_true_n, y_pred_n))\n",
    "print(sm.f1_score(y_true_n, y_pred_n, average='weighted'))\n",
    "print(sm.precision_score(y_true_n, y_pred_n,average='weighted'))\n",
    "print(sm.recall_score(y_true_n, y_pred_n,average='weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence(sentence):\n",
    "    unc_sen = sentence\n",
    "    sentence = sentence.split()\n",
    "    print(\"===\"*40)\n",
    "    print(\"Sentence: \",unc_sen)\n",
    "    print(\"===\"*40)\n",
    "    sense = graph_for_sentence(sentence,True)\n",
    "    for i in range(len(sentence)):\n",
    "    \n",
    "        if str(sense[i]) == 'none' or str(sense[i]) == 'NE':\n",
    "            print(\"Word: \",sentence[i])\n",
    "            print(\"Sense: \", sense[i])\n",
    "        else:\n",
    "            print(\"Word: \",sentence[i])\n",
    "            print(\"Sense: \", str(sense[i])[8:-2])\n",
    "            print(\"Definition of sense: \", sense[i].definition())\n",
    "        print('---'*20)\n",
    "    print(\"===\"*40)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Sentence:   He was right about turning right .\n",
      "========================================================================================================================\n",
      "Word:  He\n",
      "Sense:  helium.n.01\n",
      "Definition of sense:  a very light colorless element that is one of the six inert gasses; the most difficult gas to liquefy; occurs in economically extractable amounts in certain natural gases (as those found in Texas and Kansas)\n",
      "------------------------------------------------------------\n",
      "Word:  was\n",
      "Sense:  be.v.03\n",
      "Definition of sense:  occupy a certain position or area; be somewhere\n",
      "------------------------------------------------------------\n",
      "Word:  right\n",
      "Sense:  right.n.04\n",
      "Definition of sense:  those who support political or social or economic conservatism; those who believe that things are better left unchanged\n",
      "------------------------------------------------------------\n",
      "Word:  about\n",
      "Sense:  about.r.04\n",
      "Definition of sense:  used of movement to or among many different places or in no particular direction\n",
      "------------------------------------------------------------\n",
      "Word:  turning\n",
      "Sense:  turn.v.16\n",
      "Definition of sense:  cause to change or turn into something different;assume new characteristics\n",
      "------------------------------------------------------------\n",
      "Word:  right\n",
      "Sense:  right.n.06\n",
      "Definition of sense:  a turn toward the side of the body that is on the south when the person is facing east\n",
      "------------------------------------------------------------\n",
      "Word:  .\n",
      "Sense:  none\n",
      "------------------------------------------------------------\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "new_sentence = ' He was right about turning right .'\n",
    "test_sentence(new_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9b58781d1fa8134ac2ec6cc898ef119ce6179b951012c321b666aa023aba281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
